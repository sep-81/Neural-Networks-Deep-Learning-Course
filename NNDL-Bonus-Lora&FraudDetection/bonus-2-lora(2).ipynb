{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7361638,"sourceType":"datasetVersion","datasetId":4276194}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ! pip install pydub\n# ! pip install -U datasets\n# ! pip install -U accelerate\n# ! pip install -U transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install numpy==1.22.4","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:14:15.167592Z","iopub.execute_input":"2024-01-10T22:14:15.167973Z","iopub.status.idle":"2024-01-10T22:14:26.814220Z","shell.execute_reply.started":"2024-01-10T22:14:15.167941Z","shell.execute_reply":"2024-01-10T22:14:26.813082Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy==1.22.4 in /opt/conda/lib/python3.10/site-packages (1.22.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# how to print the nupy version:\nimport importlib\nimport numpy as np\n\n# Make some changes to the numpy module or its files\n\n# Now reload the module\n# importlib.reload(np)\n\nprint(np.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip show numpy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\ntokenizer = AutoTokenizer.from_pretrained('roberta-large')\nmodel = AutoModel.from_pretrained('roberta-large')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:14:47.163781Z","iopub.execute_input":"2024-01-10T22:14:47.164184Z","iopub.status.idle":"2024-01-10T22:15:00.309036Z","shell.execute_reply.started":"2024-01-10T22:14:47.164150Z","shell.execute_reply":"2024-01-10T22:15:00.308212Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f36d258181f4e1385a835297d054ea6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b747567b0544765b9a8c56db00fc957"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9efd27a4cfe47f4bd6cefd0ea00a992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e727f0e119ff4bca900c3eadc99a2704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca1775c77cc410081c68b160256c10a"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pwd\n# !curl -o multinli_1.0.zip https://cims.nyu.edu/~sbowman/multinli/multinli_1.0.zip\n# !unzip multinli_1.0.zip\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:15:00.310609Z","iopub.execute_input":"2024-01-10T22:15:00.311035Z","iopub.status.idle":"2024-01-10T22:15:02.279777Z","shell.execute_reply.started":"2024-01-10T22:15:00.311008Z","shell.execute_reply":"2024-01-10T22:15:02.278684Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"dir_data = \"/kaggle/working/multinli_1.0\"\ndir_data = '/kaggle/input/bonus2-lora/multinli_1.0'\nimport pandas as pd\n\n# Path to the dataset file\nfile_path = f'{dir_data}/multinli_1.0_train.jsonl'\n\n# Load the dataset\ndata = pd.read_json(file_path, lines=True)\n# print(data)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:15:02.281248Z","iopub.execute_input":"2024-01-10T22:15:02.281558Z","iopub.status.idle":"2024-01-10T22:15:15.610869Z","shell.execute_reply.started":"2024-01-10T22:15:02.281529Z","shell.execute_reply":"2024-01-10T22:15:15.610018Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(type(data))\nprint(data.info())\nprint(data.columns)\n# print(data.head(1))\n# print(data)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:15:15.612909Z","iopub.execute_input":"2024-01-10T22:15:15.613222Z","iopub.status.idle":"2024-01-10T22:15:16.146628Z","shell.execute_reply.started":"2024-01-10T22:15:15.613196Z","shell.execute_reply":"2024-01-10T22:15:16.145740Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 392702 entries, 0 to 392701\nData columns (total 11 columns):\n #   Column                  Non-Null Count   Dtype \n---  ------                  --------------   ----- \n 0   annotator_labels        392702 non-null  object\n 1   genre                   392702 non-null  object\n 2   gold_label              392702 non-null  object\n 3   pairID                  392702 non-null  object\n 4   promptID                392702 non-null  int64 \n 5   sentence1               392702 non-null  object\n 6   sentence1_binary_parse  392702 non-null  object\n 7   sentence1_parse         392702 non-null  object\n 8   sentence2               392702 non-null  object\n 9   sentence2_binary_parse  392702 non-null  object\n 10  sentence2_parse         392702 non-null  object\ndtypes: int64(1), object(10)\nmemory usage: 33.0+ MB\nNone\nIndex(['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID',\n       'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2',\n       'sentence2_binary_parse', 'sentence2_parse'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## fine-tuning","metadata":{}},{"cell_type":"code","source":"# load the datset:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import load_dataset\nimport numpy as np\nfrom datasets import ClassLabel, Value, load_metric\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained('roberta-large')\n\n# Function to tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(examples['sentence1'], examples['sentence2'],\n                      truncation=True)\n\n# Load and tokenize the dataset\n\n# dataset = load_dataset('multi_nli', split='train')\n\ndir_data = \"/kaggle/working/multinli_1.0\"\ndir_data = '/kaggle/input/bonus2-lora/multinli_1.0'\n\n# Path to the local files\ntrain_file = f'{dir_data}/multinli_1.0_train.jsonl'\nmatched_validation_file = f'{dir_data}/multinli_1.0_dev_matched.jsonl'\nmismatched_validation_file = f'{dir_data}/multinli_1.0_dev_mismatched.jsonl'\n\n# Load the datasets\ntrain_dataset = load_dataset('json', data_files={'train': train_file}, split='train')\nmatched_validation_dataset = load_dataset('json', data_files={'validation_matched': matched_validation_file}, split='validation_matched')\nmismatched_validation_dataset = load_dataset('json', data_files={'validation_mismatched': mismatched_validation_file}, split='validation_mismatched')\n# the train data is too big to load, so we load the first 10000 rows:\n# train_dataset = train_dataset.select(range(10000))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:15:16.147649Z","iopub.execute_input":"2024-01-10T22:15:16.147946Z","iopub.status.idle":"2024-01-10T22:15:32.019434Z","shell.execute_reply.started":"2024-01-10T22:15:16.147919Z","shell.execute_reply":"2024-01-10T22:15:32.018502Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-9728a3cffb4e95a6/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0396f3ab08c45f98ae8f207040ed690"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178c2b6df80a418eaccf5784a051fc77"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-9728a3cffb4e95a6/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\nDownloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-0584a5e343aa3bd7/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3f327842b034049afeb4600ce04cfdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f9638d26e544d6aa0b09f9fa935f636"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-0584a5e343aa3bd7/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\nDownloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-fbbbb5ea9042b6cd/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"227f8c1eec29476f858449150ce9d73c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47080f03acf14bc29f9b1ab4f1cd207a"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-fbbbb5ea9042b6cd/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:15:32.020630Z","iopub.execute_input":"2024-01-10T22:15:32.021353Z","iopub.status.idle":"2024-01-10T22:15:32.030012Z","shell.execute_reply.started":"2024-01-10T22:15:32.021324Z","shell.execute_reply":"2024-01-10T22:15:32.029081Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse'],\n    num_rows: 392702\n})"},"metadata":{}}]},{"cell_type":"code","source":"# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n\ntokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\ntokenized_matched_validation_dataset = matched_validation_dataset.map(tokenize_function, batched=True)\ntokenized_mismatched_validation_dataset = mismatched_validation_dataset.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:15:32.031251Z","iopub.execute_input":"2024-01-10T22:15:32.031517Z","iopub.status.idle":"2024-01-10T22:16:19.321645Z","shell.execute_reply.started":"2024-01-10T22:15:32.031493Z","shell.execute_reply":"2024-01-10T22:16:19.320874Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/393 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db21d747087645ea8b5244a5e8f1784c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f01e72222c40cda77390d49c69fb1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dca560eb4b94ce69fc0965126c89446"}},"metadata":{}}]},{"cell_type":"code","source":"tkn_trn_dta = tokenized_train_dataset\ntkn_mch_vld_dta = tokenized_matched_validation_dataset\ntkn_msmch_vld_dta = tokenized_mismatched_validation_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:16:19.322885Z","iopub.execute_input":"2024-01-10T22:16:19.323504Z","iopub.status.idle":"2024-01-10T22:16:19.328155Z","shell.execute_reply.started":"2024-01-10T22:16:19.323465Z","shell.execute_reply":"2024-01-10T22:16:19.327152Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(type(tkn_trn_dta))\nprint(tkn_mch_vld_dta)\nprint(tkn_trn_dta)\nprint(tkn_trn_dta.select([0]))\nprint(tkn_trn_dta.select([0]).to_dict()['gold_label'])","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:16:19.329377Z","iopub.execute_input":"2024-01-10T22:16:19.329702Z","iopub.status.idle":"2024-01-10T22:16:19.377195Z","shell.execute_reply.started":"2024-01-10T22:16:19.329670Z","shell.execute_reply":"2024-01-10T22:16:19.376302Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<class 'datasets.arrow_dataset.Dataset'>\nDataset({\n    features: ['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})\nDataset({\n    features: ['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse', 'input_ids', 'attention_mask'],\n    num_rows: 392702\n})\nDataset({\n    features: ['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse', 'input_ids', 'attention_mask'],\n    num_rows: 1\n})\n['neutral']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tokenized_matched_validation_dataset.column_names)\nprint(tokenized_mismatched_validation_dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:16:19.382170Z","iopub.execute_input":"2024-01-10T22:16:19.382431Z","iopub.status.idle":"2024-01-10T22:16:19.387057Z","shell.execute_reply.started":"2024-01-10T22:16:19.382407Z","shell.execute_reply":"2024-01-10T22:16:19.386006Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse', 'input_ids', 'attention_mask']\n['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse', 'input_ids', 'attention_mask']\n","output_type":"stream"}]},{"cell_type":"code","source":"label_dict = {'neutral': 0, 'contradiction': 1, 'entailment': 2}\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:16:19.388042Z","iopub.execute_input":"2024-01-10T22:16:19.388320Z","iopub.status.idle":"2024-01-10T22:16:19.397751Z","shell.execute_reply.started":"2024-01-10T22:16:19.388276Z","shell.execute_reply":"2024-01-10T22:16:19.396905Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# convert the labels to indices for all the datsets:\ntokenized_train_dataset = tokenized_train_dataset.map(lambda example: {'gold_label': label_dict[example['gold_label']]})","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:16:19.398883Z","iopub.execute_input":"2024-01-10T22:16:19.399199Z","iopub.status.idle":"2024-01-10T22:18:08.198807Z","shell.execute_reply.started":"2024-01-10T22:16:19.399175Z","shell.execute_reply":"2024-01-10T22:18:08.197858Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/392702 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f81f0dc4504c9fa11af532a9006263"}},"metadata":{}}]},{"cell_type":"code","source":"print(tokenized_train_dataset[0])\nprint(type(tokenized_matched_validation_dataset['gold_label']))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:08.200098Z","iopub.execute_input":"2024-01-10T22:18:08.200447Z","iopub.status.idle":"2024-01-10T22:18:08.221822Z","shell.execute_reply.started":"2024-01-10T22:18:08.200413Z","shell.execute_reply":"2024-01-10T22:18:08.220883Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{'annotator_labels': ['neutral'], 'genre': 'government', 'gold_label': 0, 'pairID': '31193n', 'promptID': '31193', 'sentence1': 'Conceptually cream skimming has two basic dimensions - product and geography.', 'sentence1_binary_parse': '( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )', 'sentence1_parse': '(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))', 'sentence2': 'Product and geography are what make cream skimming work. ', 'sentence2_binary_parse': '( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )', 'sentence2_parse': '(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))', 'input_ids': [0, 9157, 16771, 13851, 6353, 2972, 16364, 34, 80, 3280, 22735, 111, 1152, 8, 18947, 4, 2, 2, 41257, 8, 18947, 32, 99, 146, 6353, 2972, 16364, 173, 4, 1437, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Identify unique labels\nunique_labels = set(tokenized_mismatched_validation_dataset['gold_label'])\nlabel_to_index_val_mis = {label: idx for idx, label in enumerate(unique_labels)}\nprint(label_to_index_val_mis)\nunique_labels = set(tokenized_matched_validation_dataset['gold_label'])\nlabel_to_index_val_mtch = {label: idx for idx, label in enumerate(unique_labels)}\nlabel_to_index_val_mtch","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:08.222977Z","iopub.execute_input":"2024-01-10T22:18:08.223540Z","iopub.status.idle":"2024-01-10T22:18:08.461717Z","shell.execute_reply.started":"2024-01-10T22:18:08.223509Z","shell.execute_reply":"2024-01-10T22:18:08.460674Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"{'contradiction': 0, 'neutral': 1, 'entailment': 2, '-': 3}\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'contradiction': 0, 'neutral': 1, '-': 2, 'entailment': 3}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_matched_validation_dataset = tokenized_matched_validation_dataset.filter(lambda example: example['gold_label'] != '-')\ntokenized_mismatched_validation_dataset = tokenized_mismatched_validation_dataset.filter(lambda example: example['gold_label'] != '-')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:08.463095Z","iopub.execute_input":"2024-01-10T22:18:08.463456Z","iopub.status.idle":"2024-01-10T22:18:10.548644Z","shell.execute_reply.started":"2024-01-10T22:18:08.463422Z","shell.execute_reply":"2024-01-10T22:18:10.547800Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dfe5c615dd7473983d3850b010895d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4b2157ec2149d5ac1e1152e375eff8"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_matched_validation_dataset = tokenized_matched_validation_dataset.map(lambda example: {'gold_label': label_dict[example['gold_label']]})\ntokenized_mismatched_validation_dataset = tokenized_mismatched_validation_dataset.map(lambda example: {'gold_label': label_dict[example['gold_label']]})","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:10.549821Z","iopub.execute_input":"2024-01-10T22:18:10.550130Z","iopub.status.idle":"2024-01-10T22:18:16.418752Z","shell.execute_reply.started":"2024-01-10T22:18:10.550104Z","shell.execute_reply":"2024-01-10T22:18:16.417881Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9815 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3815f71b3e35468a92b078825a60a44a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9832 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41af8d3d2f5b4fb78cb4a4077b33c562"}},"metadata":{}}]},{"cell_type":"code","source":"# see the tokenized dataset:\nprint(type(tokenized_train_dataset[0]))\nprint(tokenized_train_dataset[0].keys())\nprint(tokenized_train_dataset.column_names)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:16.420043Z","iopub.execute_input":"2024-01-10T22:18:16.420406Z","iopub.status.idle":"2024-01-10T22:18:16.426974Z","shell.execute_reply.started":"2024-01-10T22:18:16.420370Z","shell.execute_reply":"2024-01-10T22:18:16.426118Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<class 'dict'>\ndict_keys(['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse', 'input_ids', 'attention_mask'])\n['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID', 'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2', 'sentence2_binary_parse', 'sentence2_parse', 'input_ids', 'attention_mask']\n","output_type":"stream"}]},{"cell_type":"code","source":"# run this if and only if sth failed.\n# tokenized_train_dataset = tkn_trn_dta\n# tokenized_matched_validation_dataset = tkn_mch_vld_dta\n# tokenized_mismatched_validation_dataset = tkn_msmch_vld_dta","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:16.428095Z","iopub.execute_input":"2024-01-10T22:18:16.428353Z","iopub.status.idle":"2024-01-10T22:18:16.458383Z","shell.execute_reply.started":"2024-01-10T22:18:16.428329Z","shell.execute_reply":"2024-01-10T22:18:16.457592Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# # Format our dataset to outputs torch.Tensor\n# tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"pairID\", \"promptID\", \"genre\", \"label1\", \"label2\", \"label3\", \"label4\", \"label5\"])\n# tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n# tokenized_datasets.set_format('torch')\n\n\n\ncolumns_to_remove = [\"annotator_labels\", \"sentence1\", \"pairID\", \"promptID\", \"genre\",\n                     \"sentence1_binary_parse\", \"sentence1_parse\", \"sentence2\", \"sentence2_binary_parse\", \"sentence2_parse\"]\n\ntokenized_train_dataset = tokenized_train_dataset.remove_columns(columns_to_remove)\ntokenized_train_dataset = tokenized_train_dataset.rename_column(\"gold_label\", \"labels\")\ntokenized_train_dataset.set_format('torch')\n\ntokenized_matched_validation_dataset = tokenized_matched_validation_dataset.remove_columns(columns_to_remove)\ntokenized_matched_validation_dataset = tokenized_matched_validation_dataset.rename_column(\"gold_label\", \"labels\")\ntokenized_matched_validation_dataset.set_format('torch')\n\ntokenized_mismatched_validation_dataset = tokenized_mismatched_validation_dataset.remove_columns(columns_to_remove)\ntokenized_mismatched_validation_dataset = tokenized_mismatched_validation_dataset.rename_column(\"gold_label\", \"labels\")\ntokenized_mismatched_validation_dataset.set_format('torch')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:01.842198Z","iopub.execute_input":"2024-01-10T22:51:01.843072Z","iopub.status.idle":"2024-01-10T22:51:01.937015Z","shell.execute_reply.started":"2024-01-10T22:51:01.843038Z","shell.execute_reply":"2024-01-10T22:51:01.935881Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# # Split the dataset into training and validation\ntokenized_train_dataset = tokenized_train_dataset.shuffle(seed=42).select(range(2000,3000))  # Use a smaller subset for training\ntokenized_matched_validation_dataset = tokenized_matched_validation_dataset.shuffle(seed=42).select(range(1000, 1100))  # Use a different subset for evaluation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # remove the column 'annotator_labels' from the datasets:\n# columns_to_remove = ['annotator_labels']\n# tokenized_train_dataset = tokenized_train_dataset.remove_columns(columns_to_remove)\n# tokenized_matched_validation_dataset = tokenized_matched_validation_dataset.remove_columns(columns_to_remove)\n# tokenized_mismatched_validation_dataset = tokenized_mismatched_validation_dataset.remove_columns(columns_to_remove)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:28.281136Z","iopub.status.idle":"2024-01-10T22:51:28.281613Z","shell.execute_reply.started":"2024-01-10T22:51:28.281361Z","shell.execute_reply":"2024-01-10T22:51:28.281385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(tokenized_train_dataset))\nprint(tokenized_train_dataset.format)\nprint(tokenized_train_dataset)\nprint(tokenized_train_dataset.select([0]))\nprint(tokenized_train_dataset.select([0]).to_dict()['labels'])","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:28.410129Z","iopub.execute_input":"2024-01-10T22:51:28.410414Z","iopub.status.idle":"2024-01-10T22:51:28.424507Z","shell.execute_reply.started":"2024-01-10T22:51:28.410387Z","shell.execute_reply":"2024-01-10T22:51:28.423635Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"<class 'datasets.arrow_dataset.Dataset'>\n{'type': 'torch', 'format_kwargs': {}, 'columns': ['labels', 'input_ids', 'attention_mask'], 'output_all_columns': False}\nDataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 1000\n})\nDataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 1\n})\n[0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# find the unique labels:\nlabels = set()\nfor idx in range(100):\n    labels.add(tokenized_train_dataset.select([idx]).to_dict()['labels'][0])","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:28.591463Z","iopub.execute_input":"2024-01-10T22:51:28.591724Z","iopub.status.idle":"2024-01-10T22:51:28.890373Z","shell.execute_reply.started":"2024-01-10T22:51:28.591701Z","shell.execute_reply":"2024-01-10T22:51:28.889608Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"print(labels)\nlabel_dict = {'neutral': 0, 'contradiction': 1, 'entailment': 2}\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:28.892054Z","iopub.execute_input":"2024-01-10T22:51:28.892628Z","iopub.status.idle":"2024-01-10T22:51:28.897137Z","shell.execute_reply.started":"2024-01-10T22:51:28.892586Z","shell.execute_reply":"2024-01-10T22:51:28.896237Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"{0, 1, 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"# tokenized_train_dataset.reset_format()\n# print(tokenized_train_dataset[0])\n# tokenized_train_dataset.set_format('torch')\n# print(tokenized_train_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:29.000334Z","iopub.execute_input":"2024-01-10T22:51:29.000579Z","iopub.status.idle":"2024-01-10T22:51:29.005518Z","shell.execute_reply.started":"2024-01-10T22:51:29.000557Z","shell.execute_reply":"2024-01-10T22:51:29.004739Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"# for example in tokenized_train_dataset:\n#     print(example['labels'])\n    \n# see the tokenized dataset:\nprint(type(tokenized_train_dataset))\nprint(tokenized_train_dataset.format)\nprint(tokenized_train_dataset[0])\nprint(tokenized_train_dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:30.451627Z","iopub.execute_input":"2024-01-10T22:51:30.451941Z","iopub.status.idle":"2024-01-10T22:51:30.459725Z","shell.execute_reply.started":"2024-01-10T22:51:30.451913Z","shell.execute_reply":"2024-01-10T22:51:30.458811Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"<class 'datasets.arrow_dataset.Dataset'>\n{'type': 'torch', 'format_kwargs': {}, 'columns': ['labels', 'input_ids', 'attention_mask'], 'output_all_columns': False}\n{'labels': tensor(0), 'input_ids': tensor([    0,   250, 22040,     9, 16045, 20536,  2640,  2074,  1595,    30,\n          982,     8,  1822,    81,     5,    94,   891,     9,   107,   492,\n         4674,     5,   476,     7,   146,  1041,   582,    13, 13430,  6848,\n           50, 10946, 15789,    19,    49,  1159,     4,     2,     2,   133,\n         1041,    32,    45,   182,  1372,    59,     5,    92,  4361,    14,\n         4674,    33,     4,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1])}\n['labels', 'input_ids', 'attention_mask']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\";\")","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:30.629653Z","iopub.execute_input":"2024-01-10T22:51:30.629949Z","iopub.status.idle":"2024-01-10T22:51:30.634265Z","shell.execute_reply.started":"2024-01-10T22:51:30.629924Z","shell.execute_reply":"2024-01-10T22:51:30.633351Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":";\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n# os.environ[\"WANDB_DISABLED\"] = \"true\"\n# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:30.851738Z","iopub.execute_input":"2024-01-10T22:51:30.852075Z","iopub.status.idle":"2024-01-10T22:51:30.856477Z","shell.execute_reply.started":"2024-01-10T22:51:30.852048Z","shell.execute_reply":"2024-01-10T22:51:30.855363Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# Load the model\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-large', num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:32.408976Z","iopub.execute_input":"2024-01-10T22:51:32.409320Z","iopub.status.idle":"2024-01-10T22:51:33.074515Z","shell.execute_reply.started":"2024-01-10T22:51:32.409292Z","shell.execute_reply":"2024-01-10T22:51:33.073787Z"},"trusted":true},"execution_count":138,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)\nprint(sum(p.numel() for p in model.parameters() if p.requires_grad))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:33.076482Z","iopub.execute_input":"2024-01-10T22:51:33.076823Z","iopub.status.idle":"2024-01-10T22:51:33.087068Z","shell.execute_reply.started":"2024-01-10T22:51:33.076788Z","shell.execute_reply":"2024-01-10T22:51:33.086200Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stdout","text":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n  )\n)\n355362819\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nimport torch\n\nclass CustomDataCollator:\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n\n    def __call__(self, examples):\n        # Assuming 'examples' is a batch from your dataset\n        input_ids = [example['input_ids'].clone().detach() for example in examples]\n        attention_masks = [example['attention_mask'].clone().detach() for example in examples]\n        labels = torch.tensor([example['labels'] for example in examples])\n        print(labels, labels.dtype)\n        input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n        attention_masks_padded = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n\n        return {\n            'input_ids': input_ids_padded,\n            'attention_mask': attention_masks_padded,\n            'labels': labels\n        }\n\n    \ndata_collator = CustomDataCollator(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T23:19:50.686891Z","iopub.execute_input":"2024-01-10T23:19:50.687253Z","iopub.status.idle":"2024-01-10T23:19:50.695720Z","shell.execute_reply.started":"2024-01-10T23:19:50.687226Z","shell.execute_reply":"2024-01-10T23:19:50.694704Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"print(\"Train dataset size:\", len(tokenized_train_dataset))\nprint(\"Example data:\", tokenized_train_dataset[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:33.118483Z","iopub.execute_input":"2024-01-10T22:51:33.119061Z","iopub.status.idle":"2024-01-10T22:51:33.125901Z","shell.execute_reply.started":"2024-01-10T22:51:33.119035Z","shell.execute_reply":"2024-01-10T22:51:33.125097Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"Train dataset size: 1000\nExample data: {'labels': tensor(0), 'input_ids': tensor([    0,   250, 22040,     9, 16045, 20536,  2640,  2074,  1595,    30,\n          982,     8,  1822,    81,     5,    94,   891,     9,   107,   492,\n         4674,     5,   476,     7,   146,  1041,   582,    13, 13430,  6848,\n           50, 10946, 15789,    19,    49,  1159,     4,     2,     2,   133,\n         1041,    32,    45,   182,  1372,    59,     5,    92,  4361,    14,\n         4674,    33,     4,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1])}\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# def compute_metrics(eval_pred):\n#     print(eval_pred)\n#     logits, labels = eval_pred\n#     predictions = logits.argmax(axis=-1)\n#     return {'accuracy': accuracy_score(labels, predictions)}\n\ndef compute_metrics(pred):\n#     print(eval_pred)\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    return {'accuracy': acc}\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:33.687586Z","iopub.execute_input":"2024-01-10T22:51:33.687856Z","iopub.status.idle":"2024-01-10T22:51:33.692934Z","shell.execute_reply.started":"2024-01-10T22:51:33.687818Z","shell.execute_reply":"2024-01-10T22:51:33.691970Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          \n    num_train_epochs=3,              \n    per_device_train_batch_size=4,   \n    gradient_accumulation_steps=2,\n    eval_steps=20,\n    evaluation_strategy = 'steps',\n    per_device_eval_batch_size=64,   \n    warmup_steps=500,                \n    weight_decay=0.01,               \n    logging_dir='./logs',           \n    logging_steps=20,\n    report_to='none',\n    do_train=True,\n    do_eval=True,\n    do_predict=True,\n#     fp16=True,\n)\n\n# Initialize our Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_matched_validation_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics \n)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:34.121640Z","iopub.execute_input":"2024-01-10T22:51:34.121936Z","iopub.status.idle":"2024-01-10T22:51:34.466095Z","shell.execute_reply.started":"2024-01-10T22:51:34.121910Z","shell.execute_reply":"2024-01-10T22:51:34.465116Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"# free gpu memory:\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n# free gpu memory:\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:34.467828Z","iopub.execute_input":"2024-01-10T22:51:34.468200Z","iopub.status.idle":"2024-01-10T22:51:35.996444Z","shell.execute_reply.started":"2024-01-10T22:51:34.468166Z","shell.execute_reply":"2024-01-10T22:51:35.995641Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"# calculate the time:\nimport time\nstart_time = time.time()\n\n# Train the model\ntrainer.train()\n\n# calculate the time:\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\n# You can save the model and tokenizer\ntrainer.save_model(\"./multi_nli_roberta\")\ntokenizer.save_pretrained(\"./multi_nli_roberta\")","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:51:35.997879Z","iopub.execute_input":"2024-01-10T22:51:35.998171Z","iopub.status.idle":"2024-01-10T22:53:40.388770Z","shell.execute_reply.started":"2024-01-10T22:51:35.998144Z","shell.execute_reply":"2024-01-10T22:53:40.387792Z"},"trusted":true},"execution_count":145,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 02:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.129600</td>\n      <td>1.097398</td>\n      <td>0.360000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.096700</td>\n      <td>1.104369</td>\n      <td>0.350000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.103000</td>\n      <td>1.104729</td>\n      <td>0.310000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.111700</td>\n      <td>1.095781</td>\n      <td>0.360000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.083100</td>\n      <td>1.072380</td>\n      <td>0.450000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.048400</td>\n      <td>0.978953</td>\n      <td>0.510000</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.977800</td>\n      <td>1.115750</td>\n      <td>0.480000</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.969500</td>\n      <td>0.844807</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.827200</td>\n      <td>0.827574</td>\n      <td>0.660000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.783700</td>\n      <td>0.718026</td>\n      <td>0.740000</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.785500</td>\n      <td>0.701595</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.690300</td>\n      <td>0.656714</td>\n      <td>0.760000</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.654500</td>\n      <td>0.842123</td>\n      <td>0.670000</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.792900</td>\n      <td>1.051706</td>\n      <td>0.700000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.697400</td>\n      <td>0.563938</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.343000</td>\n      <td>0.620144</td>\n      <td>0.820000</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.741200</td>\n      <td>0.558669</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.423300</td>\n      <td>0.899748</td>\n      <td>0.780000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"--- 122.53531670570374 seconds ---\n","output_type":"stream"},{"execution_count":145,"output_type":"execute_result","data":{"text/plain":"('./multi_nli_roberta/tokenizer_config.json',\n './multi_nli_roberta/special_tokens_map.json',\n './multi_nli_roberta/vocab.json',\n './multi_nli_roberta/merges.txt',\n './multi_nli_roberta/added_tokens.json',\n './multi_nli_roberta/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# free gpu memory:\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n# free gpu memory:\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:44:14.993381Z","iopub.status.idle":"2024-01-10T22:44:14.993743Z","shell.execute_reply.started":"2024-01-10T22:44:14.993560Z","shell.execute_reply":"2024-01-10T22:44:14.993578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # calculate the time:\n# import time\n# start_time = time.time()\n\n# # Evaluate the model\n# eval_result = trainer.evaluate(tokenized_matched_validation_dataset)\n\n# # evaluate the model  on the mismatched validation dataset:\n# trainer.evaluate(tokenized_mismatched_validation_dataset)\n\n# # calculate the time:\n# print(\"--- %s seconds ---\" % (time.time() - start_time))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:19.951864Z","iopub.execute_input":"2024-01-10T22:18:19.952213Z","iopub.status.idle":"2024-01-10T22:18:19.961914Z","shell.execute_reply.started":"2024-01-10T22:18:19.952184Z","shell.execute_reply":"2024-01-10T22:18:19.961020Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# free gpu memory:\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n# free gpu memory:\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:19.963256Z","iopub.execute_input":"2024-01-10T22:18:19.963645Z","iopub.status.idle":"2024-01-10T22:18:20.785962Z","shell.execute_reply.started":"2024-01-10T22:18:19.963612Z","shell.execute_reply":"2024-01-10T22:18:20.784963Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## LoRA","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:18:20.787537Z","iopub.execute_input":"2024-01-10T22:18:20.787953Z","iopub.status.idle":"2024-01-10T22:18:32.805422Z","shell.execute_reply.started":"2024-01-10T22:18:20.787915Z","shell.execute_reply":"2024-01-10T22:18:32.804226Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting peft\n  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/8b/1b/aee2a330d050c493642d59ba6af51f3910cb138ea48ede228c84c204a5af/peft-0.7.1-py3-none-any.whl.metadata\n  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.22.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.36.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.1)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fine-tuning using the LoRA approach:\nfrom peft import LoraConfig\nfrom transformers import RobertaForSequenceClassification\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=16,\n    target_modules=[\"query\", \"value\"],  # Specify which modules to apply LoRA\n    lora_dropout=0.1,\n    bias=\"none\",\n    modules_to_save=[\"classifier\"],  # Specify modules to keep trainable\n)\n\nfrom peft import get_peft_model\n\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-large', num_labels=3)\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T23:19:59.671217Z","iopub.execute_input":"2024-01-10T23:19:59.671592Z","iopub.status.idle":"2024-01-10T23:20:00.322952Z","shell.execute_reply.started":"2024-01-10T23:19:59.671561Z","shell.execute_reply":"2024-01-10T23:20:00.322012Z"},"trusted":true},"execution_count":172,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def count_trainable_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(model)\n\n# After applying LoRA modifications to your model\nnum_trainable_params = count_trainable_parameters(model)\nprint(f\"Number of trainable parameters: {num_trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-10T23:35:08.951741Z","iopub.execute_input":"2024-01-10T23:35:08.952472Z","iopub.status.idle":"2024-01-10T23:35:08.969414Z","shell.execute_reply.started":"2024-01-10T23:35:08.952435Z","shell.execute_reply":"2024-01-10T23:35:08.968510Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"PeftModel(\n  (base_model): LoraModel(\n    (model): RobertaForSequenceClassification(\n      (roberta): RobertaModel(\n        (embeddings): RobertaEmbeddings(\n          (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n          (position_embeddings): Embedding(514, 1024, padding_idx=1)\n          (token_type_embeddings): Embedding(1, 1024)\n          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): RobertaEncoder(\n          (layer): ModuleList(\n            (0-23): 24 x RobertaLayer(\n              (attention): RobertaAttention(\n                (self): RobertaSelfAttention(\n                  (query): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n                  (value): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): RobertaSelfOutput(\n                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): RobertaIntermediate(\n                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): RobertaOutput(\n                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n      )\n      (classifier): ModulesToSaveWrapper(\n        (original_module): RobertaClassificationHead(\n          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n        )\n        (modules_to_save): ModuleDict(\n          (default): RobertaClassificationHead(\n            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n          )\n        )\n      )\n    )\n  )\n)\nNumber of trainable parameters: 2625539\n","output_type":"stream"}]},{"cell_type":"code","source":"# data_collator2 = CustomDataCollator(tokenizer)\nfrom transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\nprint(\"Training dataset size:\", len(tokenized_train_dataset))\nprint(\"Mismatched validation dataset size:\", len(tokenized_mismatched_validation_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T23:31:00.155522Z","iopub.execute_input":"2024-01-10T23:31:00.156149Z","iopub.status.idle":"2024-01-10T23:31:00.161683Z","shell.execute_reply.started":"2024-01-10T23:31:00.156113Z","shell.execute_reply":"2024-01-10T23:31:00.160755Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"Training dataset size: 1000\nMismatched validation dataset size: 9832\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          \n    num_train_epochs=3,              \n    per_device_train_batch_size=1,   \n#     gradient_accumulation_steps=2,\n    eval_steps=20,\n    evaluation_strategy = 'steps',\n    per_device_eval_batch_size=64,   \n    warmup_steps=500,                \n    weight_decay=0.01,               \n    logging_dir='./logs',           \n    logging_steps=20,\n    report_to='none',\n    do_train=True,\n    do_eval=True,\n    do_predict=True,\n#     fp16=True,\n)\n\n# Initialize our Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n#     train_dataset=tokenized_train_dataset,\n    train_dataset=tokenized_mismatched_validation_dataset,\n#     eval_dataset=tokenized_matched_validation_dataset,\n#     data_collator=data_collator,\n    compute_metrics=compute_metrics \n)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T23:32:52.498495Z","iopub.execute_input":"2024-01-10T23:32:52.498888Z","iopub.status.idle":"2024-01-10T23:32:52.518249Z","shell.execute_reply.started":"2024-01-10T23:32:52.498846Z","shell.execute_reply":"2024-01-10T23:32:52.517279Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"# Calculate time:\nimport time\nstart_time = time.time()\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model\neval_result = trainer.evaluate()\n\n# evaluate the model  on the mismatched validation dataset:\ntrainer.evaluate(tokenized_mismatched_validation_dataset)\n\n# calculate the time:\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\n# You can save the model and tokenizer\ntrainer.save_model(\"./multi_nli_roberta_lora\")\ntokenizer.save_pretrained(\"./multi_nli_roberta_lora\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}